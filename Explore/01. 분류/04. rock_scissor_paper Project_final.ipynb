{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /home/aiffel0047/anaconda3/lib/python3.7/site-packages (7.0.0)\n",
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PIL 라이브러리가 설치되어 있지 않다면 설치\n",
    "!pip install pillow   \n",
    "\n",
    "from PIL import Image\n",
    "import os, glob\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0047/aiffel/rock_scissor_paper/scissor\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0047/aiffel/rock_scissor_paper/paper\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 디렉토리 경로:  /home/aiffel0047/aiffel/rock_scissor_paper/rock\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토import os\n",
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "print(\"이미지 디렉토리 경로: \", image_dir_path)\n",
    "\n",
    "images=glob.glob(image_dir_path + \"/*.jpg\")  \n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "target_size=(28,28)\n",
    "for img in images:\n",
    "    old_img=Image.open(img)\n",
    "    new_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "    new_img.save(img,\"JPEG\")\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 1741 입니다.\n",
      "x_train shape: (1741, 28, 28, 3)\n",
      "y_train shape: (1741,)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드하기\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=1741   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train) =load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 딥러닝 네트워크 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 8)         224       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 8)         584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 5, 5, 8)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                6432      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 7,339\n",
      "Trainable params: 7,339\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(8, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(8, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55/55 [==============================] - 4s 73ms/step - loss: 1.0961 - accuracy: 0.3596\n",
      "Epoch 2/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.0710 - accuracy: 0.4578\n",
      "Epoch 3/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 1.0014 - accuracy: 0.5095\n",
      "Epoch 4/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.9254 - accuracy: 0.5750\n",
      "Epoch 5/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.8521 - accuracy: 0.6324\n",
      "Epoch 6/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.8031 - accuracy: 0.6640\n",
      "Epoch 7/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.7394 - accuracy: 0.6973\n",
      "Epoch 8/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.6875 - accuracy: 0.7295\n",
      "Epoch 9/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.6288 - accuracy: 0.7559\n",
      "Epoch 10/10\n",
      "55/55 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f22b00c4510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_norm, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터(x_test)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (303, 28, 28, 3)\n",
      "y_test shape: (303,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 테스트 데이터 로드하기\n",
    "\n",
    "def load_data(img_path):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    number_of_data=303   # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1       \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"테스트 데이터(x_test)의 이미지 개수는\",idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper_test\"\n",
    "(x_test, y_test) =load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test_reshaped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-deefb4f65998>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test_accuracy 측정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_reshaped\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_loss: {} \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_accuracy: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test_reshaped' is not defined"
     ]
    }
   ],
   "source": [
    "# test_accuracy 측정\n",
    "\n",
    "x_train_reshaped=x_train_norm.reshape( -1, 28, 28, 1)  # 데이터갯수에 -1을 쓰면 reshape시 자동계산됩니다.\n",
    "x_test_reshaped=x_test_norm.reshape( -1, 28, 28, 1\n",
    "test_loss, test_accuracy = model.evaluate(x_test_reshaped,y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.predict() 결과 :  [9.9999678e-01 2.5531106e-06 7.1405424e-07]\n",
      "model이 추론한 가장 가능성이 높은 결과 :  0\n",
      "실제 데이터의 라벨 :  0\n"
     ]
    }
   ],
   "source": [
    "predicted_result = model.predict(x_test_reshaped)  # model이 추론한 확률값. \n",
    "predicted_labels = np.argmax(predicted_result, axis=1)\n",
    "\n",
    "idx=20  #1번째 x_test를 살펴보자. \n",
    "print('model.predict() 결과 : ', predicted_result[idx])\n",
    "print('model이 추론한 가장 가능성이 높은 결과 : ', predicted_labels[idx])\n",
    "print('실제 데이터의 라벨 : ', y_test[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting Note\n",
    "\n",
    "데이터 준비까지는 학습 자료를 따라 차근차근 따라왔으나 문제는 웹캠이 작동하지 않을 때 부터 발생했습니다. 컴퓨터에 저장되어 있는 기존 사진 파일을 통해 계속 진행하는 방법과 코치님의 도움으로 다시 진행할 수 있었습니다. 데이터 설계에서 계속 정확도 1.00이 발생하여 모든 코드를 일일이 점검한 결과, 사진 개수에서 오타를 냈다는 사실을 알고 수정했습니다. 테스트 데이터를 통해 모델 성능을 평가하자 20%가 채 안되는 결과가 나와 설계에 들어가는 수치를 2시간 동안 고쳐 겨우 40%를 넘겼습니다. 그런데 새로고침을 하니 또 다시 30% 대로 내려왔습니다. 알고 보니 학습 데이터셋과 테스트 데이터셋의 사진이 너무 다른 게 원인이었습니다. 폴더 별로 사진을 섞다 사진 이름이 섞이는 바람에 수정하려면 시간이 더 걸릴 것 같습니다. 과연 시간 안에 낼 수 있을지 걱정이 됩니다. \n",
    "\n",
    "그리고 마침내 정확도 70%를 넘겼습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
