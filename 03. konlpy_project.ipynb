{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 형태소 분석기 변경하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-1. 데이터 수집 및 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>▶제21대 총선 실시간 개표 현황 및 결과 보기\\n\\n총선에서 여당이 다시 한 번 ...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[뉴욕=AP/뉴시스]지난 10일 뉴욕 증권거래소 건물에 미국 국기가 게양되어 있다....</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>부산지역 주유소에서 판매하는 기름값이 휘발유는 평균 1200원대, 경유는 1000원...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>담배업계가 소비자의 취향을 저격한 다양한 담배 신제품들을 잇달아 선보이고 있다.이전...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news code\n",
       "0  기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...   경제\n",
       "1  ▶제21대 총선 실시간 개표 현황 및 결과 보기\\n\\n총선에서 여당이 다시 한 번 ...   경제\n",
       "2  [뉴욕=AP/뉴시스]지난 10일 뉴욕 증권거래소 건물에 미국 국기가 게양되어 있다....   경제\n",
       "3  부산지역 주유소에서 판매하는 기름값이 휘발유는 평균 1200원대, 경유는 1000원...   경제\n",
       "4  담배업계가 소비자의 취향을 저격한 다양한 담배 신제품들을 잇달아 선보이고 있다.이전...   경제"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "csv_path = os.getenv(\"HOME\") + \"/workplace/aiffel/Explore/03. news_crawler/news_data2.csv\"\n",
    "df = pd.read_table(csv_path, sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드 확인\n",
    "idx2word = {'101' : '경제', '102' : '사회', '103' : '생활/문화', '105' : 'IT/과학'}\n",
    "code_list = [101, 102, 103, 105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "      <td>[사진=Sinenkiy/gettyimagesbank] [사진=Sinenkiy/get...</td>\n",
       "      <td>생활/문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>현대자동차가 올해 1분기(1~3월) 베트남에서 일본 도요타를 제치고 판매량 1위에 ...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>[이데일리 오토in] 카가이 남현수 기자= “이거 사진보다 실물 디자인이 더 쥑이는...</td>\n",
       "      <td>생활/문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>레고켐바이오사이언스(대표 김용주·사진)가 글로벌 기술수출에 또다시 성공했다. 201...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>출마자 공약 들여다보니\\n\\n\\n\\n구체적 공약 포함시킨 출마자 단 3명…대부분 시...</td>\n",
       "      <td>생활/문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>AI \"치료제는 2년 반, 백신은 5년 뒤에나 나온다\"\\n\\n같은 코로나 바이러스인...</td>\n",
       "      <td>IT/과학</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2744</th>\n",
       "      <td>2020년 4월 15일 수요일 (음력 3월 23일)쥐 - 재물 : 무난 건강 : 양...</td>\n",
       "      <td>생활/문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1687</th>\n",
       "      <td>기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>조선DB. 조선DB.\\n\\n한국가스공사가 실시한 배전반 구매 입찰에서 담합행위를 한...</td>\n",
       "      <td>경제</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   news   code\n",
       "2366  [사진=Sinenkiy/gettyimagesbank] [사진=Sinenkiy/get...  생활/문화\n",
       "889   현대자동차가 올해 1분기(1~3월) 베트남에서 일본 도요타를 제치고 판매량 1위에 ...     경제\n",
       "2377  [이데일리 오토in] 카가이 남현수 기자= “이거 사진보다 실물 디자인이 더 쥑이는...  생활/문화\n",
       "1150  기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...     사회\n",
       "3390  레고켐바이오사이언스(대표 김용주·사진)가 글로벌 기술수출에 또다시 성공했다. 201...  IT/과학\n",
       "2486  출마자 공약 들여다보니\\n\\n\\n\\n구체적 공약 포함시킨 출마자 단 3명…대부분 시...  생활/문화\n",
       "3216  AI \"치료제는 2년 반, 백신은 5년 뒤에나 나온다\"\\n\\n같은 코로나 바이러스인...  IT/과학\n",
       "2744  2020년 4월 15일 수요일 (음력 3월 23일)쥐 - 재물 : 무난 건강 : 양...  생활/문화\n",
       "1687  기사 섹션 분류 안내\\n\\n기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다...     사회\n",
       "649   조선DB. 조선DB.\\n\\n한국가스공사가 실시한 배전반 구매 입찰에서 담합행위를 한...     경제"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 확인\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       기사 섹션 분류 안내기사의 섹션 정보는 해당 언론사의 분류를 따르고 있습니다 언론사...\n",
       "1       제대 총선 실시간 개표 현황 및 결과 보기총선에서 여당이 다시 한 번 승리를 거두면...\n",
       "2       뉴욕뉴시스지난 일 뉴욕 증권거래소 건물에 미국 국기가 게양되어 있다 신종 코로나바이...\n",
       "3       부산지역 주유소에서 판매하는 기름값이 휘발유는 평균 원대 경유는 원대에 돌입했다일 ...\n",
       "4       담배업계가 소비자의 취향을 저격한 다양한 담배 신제품들을 잇달아 선보이고 있다이전까...\n",
       "                              ...                        \n",
       "3698    레고켐바이오사이언스대표 김용주사진가 글로벌 기술수출에 또다시 성공했다 년 중국 포순...\n",
       "3699    제대 국회의원선거 기간 중단됐던 네이버 실시간 급상승 검색어 서비스가 일 오후 시부...\n",
       "3700    아마존 연합뉴스 자료사진 아마존 연합뉴스 자료사진직원들 코로나 확산 방지 조치 충분...\n",
       "3701    제대 국회의원선거가 임박한 가운데 투표 및 개표 방송을 준비하는 기업들의 움직임이 ...\n",
       "3702    롤 점검이 일 진행될 예정이다온라인게임 리그오브레전드이하 롤은 일 오전 시부터 오전...\n",
       "Name: news, Length: 3703, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정규 표현식을 이용해서 한글 외의 문자는 전부 제거합니다.\n",
    "df['news'] = df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['news'] = df['news'].str.replace(\"\\n\",\"\")\n",
    "df['news']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news    0\n",
      "code    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "뉴스 기사의 개수:  2137\n"
     ]
    }
   ],
   "source": [
    "## 중복 샘플 제거\n",
    "df.drop_duplicates(subset=['news'], inplace=True)\n",
    "\n",
    "print('뉴스 기사의 개수: ',len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fea1b3f6110>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "##3 데이터 탐색\n",
    "import matplotlib\n",
    "import matplotlib.font_manager as fm\n",
    "fm.get_fontconfig_fonts()\n",
    "font_location ='/home/aiffel0047/anaconda3/envs/aiffel/lib/python3.7/site-packages/matplotlib/__init__.py'\n",
    "fprop = fm.FontProperties(fname=font_location)\n",
    "df['code'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. 나이브 베이즈 분류 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. Konlpy 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3-1. Mecab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Mecab\n",
    "tokenizer = Mecab()\n",
    "# 불용어 제거\n",
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']\n",
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    #- 토큰화\n",
    "    temp_data = tokenizer.morphs(sentence) \n",
    "    #- 불용어 제거\n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기사 섹션 분류 안내 기사 섹션 정보 해당 언론사 분류 를 따르 고 습니다 언론사 개별 기사 를 개 이상 섹션 으로 중복 분류 ㄹ 습니다 닫기\n"
     ]
    }
   ],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.00      0.00      0.00        59\n",
      "          경제       0.63      0.98      0.77       233\n",
      "          사회       0.92      0.93      0.93       132\n",
      "       생활/문화       0.97      0.34      0.51       111\n",
      "\n",
      "    accuracy                           0.73       535\n",
      "   macro avg       0.63      0.56      0.55       535\n",
      "weighted avg       0.70      0.73      0.67       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0047/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "# 데이터 학습\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 테스트\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-2. Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum\n",
    "hannanum = Hannanum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']\n",
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    #- 토큰화\n",
    "    temp_data = hannanum.morphs(sentence) \n",
    "    #- 불용어 제거\n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "# print(text_data[80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.00      0.00      0.00        59\n",
      "          경제       0.61      0.98      0.75       233\n",
      "          사회       0.92      0.92      0.92       132\n",
      "       생활/문화       0.97      0.25      0.40       111\n",
      "\n",
      "    accuracy                           0.71       535\n",
      "   macro avg       0.62      0.54      0.52       535\n",
      "weighted avg       0.69      0.71      0.64       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0047/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "# 데이터 학습\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 테스트\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-3. Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "kkma = Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']\n",
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    #- 토큰화\n",
    "    temp_data = kkma.morphs(sentence) \n",
    "    #- 불용어 제거\n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데일리 박 태진 다음 일자 데일리 신문 주요 기사 면 민주 연승 자만 말 고 협치 로 경제 살리 어야 감산 약발 안 통해 바닥 뚫리 ㄴ 유 또 달러 아래 로 투표율 년 만 최고 국민 목 소리 커지 었 총선 투표율 분석 코로나 도 못 막 민심 투표율 뛰 어 민주당 환호 통합 당 침묵 황 교 안 끝 까지 지켜보 아야 사설 이번 총 서 승리자 유권자 총선 승패 갈리 ㄴ 순간 코로나 대응 호평 승기 잡 아 막말 스스로 무너지 ㄴ 도 한몫 비대 위 출범 불가 피 당권 두고 계파 갈등 재현 가능성 민생 당 지역 기반 잃 어 정의 당 캐스팅 보트 역할 약화 ㄹ 듯 총선 희비 엇갈리 ㄴ 잠룡 낙 연 차기 대선 직행 유력 황 교 안 패배 책임론 불가 피년 만 잦아들 ㄴ 국민 당 침통 대통령 국정 운영 탄력 민생 경제 회복 가속도 총선 지역별 판세 양당 대결 영 호남 지역 구도 더 뚜렷 해지 어 수도권 여당 손들 어 주 어 민주 년 만 싹쓸이 민생 당 전멸 통합 보수 텃밭 스 어 자존심 지키 어 중원 싸움 팽팽 근소 ㄴ 차로 우세 총선 화제 인물 금융 전문가 홍성 국 윤 창현 중기 김 경 만 최승 재 경제 관료 유경 주 ㄴ 체면 구기 ㄴ 해결사 은퇴 냐 비대 위원장 냐 선 천정 배 꺾 양 향자 탈북자 첫 의원 태 구민 총선 경제 전문가 제언 금융 위기 때 보다 상황 심각 골든 타임 지나 기 전 경제 회복 걷 어라 재계 서비스 산업 발전 법 규제 완화 입법 서두르 어야 한목소리 총선 ㄴ 눈 보 총선 지도 거대 양당 갈라지 ㄴ 틈 맥 못 추 ㄴ 군소 정 당국 제 트럼프 코로나 패 ㄴ 데 믹 초래 지원 중단 유엔 책임 전가 비난 코로나 직격탄 항공사 곳 조원 푸 ㄴ다 원격 근무 시장 코로나 이후 배 로 커지 ㄹ 것 경제 돈 풀기 급하 ㄴ데 운신 폭 좁 이주 열 코로나 법 개정 힘 받 나 철도 예산 따오 았 덜 니 알 고 보 니 확정 되 ㄴ 정부 사업 금융 대신 나선 카드 게 뱅 최대 주주 오르 ㄴ다 메리 츠 화재 인상 끝 으로 보험료 수술 사실상 마무리 년 전 야마 토 생명 회자 되 이유 산업 기업 코 로 나발 생존 위기 업계 임금 협상 새 국면 최악 불황 속 괜하 ㄴ 오해 사 ㄹ라 정유사 공식 회동 무산 쇼크 이동 제한 늘 며 수요 급감 투표 소 곳 스마트 폰 생 중계 선거 방송 토종 엑스레이 영상 센서 코로나 특수 산업 소비자 생활 배달 앱 도전 직구 몰 ㄹ 크 어 머스 영역 파괴 붐 나디아 퍼시픽 정인 석 신임 대표 선임 온라인 유통 리모델링 주력 한샘 매출 조 도전 주목 오비 맥주 코로나 극복 나눔 활동 주목 데일리 만나 었 습니다 산 학연 협력 모델 구축 원스톱 장학 제 도입 창업 메카 충남 대 만들 ㄹ 것 거점 국립대 첫 여성 총장 지역 사회 든든 ㄴ 울타리 역할 겠 증권 마켓 롤러 코스터 증시 가치 투자 운용 사 주식 대거 정리 실적 발표 앞당기 ㄴ 삼바 주목 어야 신용 등급 하락 현대 로템 공모 발행 고 육지 책 증권 호텔 신라 위기 맛 서 투자 팔 걷 기업 아 아 태 기업 등급 줄 하향 기업 개로 최대 집값 꺾이 어 대출 부실 우려 부동산 신탁 사 점검 높 변동성 투자자 이탈 쪼그라들 ㄴ 헤 지 펀드 다크 호스 문화 정치 소신 밝히 었 다가 득 보다 실 지원 유세 혈연 까지 만 주 쉬 고 돌아오 ㄴ 외치 어 조선 공연 갈증 단비 내리 었 네 스포츠 임성 재 한국 서 코치 모셔오 아 매이 ㄹ 홀 플레이 투어 월 무 관중 경기 로 재개 스포츠 도 한국 모범 되 ㄹ 것 유송 규 머리 고정 ㄴ 채 회전 빠르 게 몸통 스윙 해보 아요 피플 지자체 장인 플 로 언서 사한 행렬 활짝 슈퍼 엠 레이디 가가 주최 온라인 콘서트 참여 작지 만 크 ㄴ 권리 스타 인증 샷 인사 마 ㄴ 사명 복 빌 ㅂ니다 오피니언 신동 민 인생 영업 코로나 바꾸 ㄹ 대학 미래 데스크 눈 항공업 드리우 ㄴ 한진 해운 파산 그림자 부동산 보름새 억 빠지 고 호가 버티 기 사라지 어 수용성 아파트 조정 시작 되 었 나 코로나 휩쓸 ㄴ 대구 청약 시장 과열 왜 내 집 에서 살 가구 평균 보다 낮 아 사회 고 설레 ㅁ 안 고 첫 투표 자가 격리 자 아 소중 ㄴ 표 위 어 시간 특별 외출 거리 두 기 잊 시민 공원 마다 나들이 객 북적 일주일 째 확 진자 명 미만 정부 거리 두 기 끝내 ㄹ까 대학 정원 남아돌 한전 공대 설립 웨 ㄴ 말 세월 호 특수 단 개 월 째 수사 지지 부진 박 태진 종합 경제 정보 미디어 데일리 재 배포\n"
     ]
    }
   ],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.00      0.00      0.00        59\n",
      "          경제       0.63      0.98      0.77       233\n",
      "          사회       0.92      0.93      0.92       132\n",
      "       생활/문화       0.97      0.35      0.52       111\n",
      "\n",
      "    accuracy                           0.73       535\n",
      "   macro avg       0.63      0.57      0.55       535\n",
      "weighted avg       0.70      0.73      0.67       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0047/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "# 데이터 학습\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 테스트\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4. Komoran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran(userdic='/tmp/dic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']\n",
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    #- 토큰화\n",
    "    temp_data = kkma.morphs(sentence) \n",
    "    #- 불용어 제거\n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "# 데이터 학습\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 테스트\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-5. Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['에','는','은','을','했','에게','있','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스']\n",
    "# 토큰화 및 토큰화 과정에서 불용어를 제거하는 함수\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    #- 토큰화\n",
    "    temp_data = kkma.morphs(sentence) \n",
    "    #- 불용어 제거\n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = preprocessing(df['news'])\n",
    "print(text_data[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "# 데이터 학습\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 테스트\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-6. 나이브 베이즈 분류모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.00      0.00      0.00        59\n",
      "          경제       0.63      0.98      0.77       233\n",
      "          사회       0.92      0.93      0.93       132\n",
      "       생활/문화       0.97      0.34      0.51       111\n",
      "\n",
      "    accuracy                           0.73       535\n",
      "   macro avg       0.63      0.56      0.55       535\n",
      "weighted avg       0.70      0.73      0.67       535\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiffel0047/anaconda3/envs/aiffel/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "# 데이터 학습\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 테스트\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "# 예측\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-4. KoNLPy 장단점 및 처리속도, 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 처리 속도 비교 Mecab < Komoran < Okt < Hannanum <<< Kkma\n",
    "- Hannanum: 형태소 후보를 모두 반환\n",
    "- Kkma: 품사 분석 정확도 높으나, 분석 시간이 너무 오래 걸림\n",
    "- Komoran: 빈 줄이 있으면 에러 발생,\n",
    "- Okt: 텍스트를 구문별로 나누어줌\n",
    "    \n",
    "- Mecab으로 분석하는 것이 가장 효율적이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고: 각 형태소 분석기가 분석하는데 걸리는 시간 체크 코드 \n",
    "# (출처: https://anpigon.github.io/blog/busy/@anpigon/5s1aam/)\n",
    "\n",
    "'''\n",
    "import time\n",
    "from konlpy.tag import Kkma, Okt, Komoran, Hannanum, Mecab\n",
    "from steem import Steem \n",
    "from steem.blog import Blog\n",
    "\n",
    "username = 'anpigon'\n",
    "b = Blog(username)\n",
    "posts = b.all()\n",
    "# posts = b.take(10)\n",
    "\n",
    "texts = []\n",
    "for post in posts:\n",
    "  if post.body != \"\":\n",
    "    texts.append(post.body.replace('\\n', ''))\n",
    "\n",
    "pos_taggers = [('Kkma', Kkma()), ('Okt', Okt()), ('Komoran', Komoran()), ('Hannanum', Hannanum()), ('Mecab', Mecab())]\n",
    "for name, tagger in pos_taggers:\n",
    "  process_time = time.time()\n",
    "  for text in texts:\n",
    "    tagger.pos(text)\n",
    "  process_time = time.time() - process_time\n",
    "  print('module = %10s, %.3f secs' % (name, process_time))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 불용어 추가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-1. 불용어 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['로이터', '뉴스보야쥬', '넷따잡', '뷰잉', '영상보기', '채널', '출처', '뉴시스', '및', '연합뉴스', '지디넷코리아', '노컷뉴스', '한국일보', '해럴드경제', '아이뉴스', '로고뉴스', '사진제공', '전자신문', '무단전재', '에','는','은','을', '로', '되','를','당','채널','됐','경우','게','으로','했','에게', '에서', '있','적', '인', '께','고','이','의','하','한','다','과','때문','할','수','무단','따른','및','금지','전재','경향신문','기자','는데','가','등','들','파이낸셜','저작','등','뉴스','라고', '아이뉴스','뉴스레터', '전자신문인터넷','안내기사의', '앵커', '이데일리', '입니다', '중복', '무단전재', '재배포', '닫기', '도', '섹션'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-2. 불용어 추가 전후 모델 성능 비교\n",
    "- f1 정확도가 소폭 상승하나 큰 차이는 보이지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2-3. 지나치게 빈도 낮은 단어, 높은 단어 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신문기사 명, 각 페이지마다 붙는 기본 단어 삭제 시 정확도 소폭 상승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 다른 날짜 데이터 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-1. csv 파일 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "input_file = r\"/home/aiffel0047/workplace/aiffel/Explore/03. news_crawler/news_dataset\"\n",
    "output_file = r\"/home/aiffel0047/workplace/aiffel/Explore/03. news_crawler/news_dataset/total_data.csv\"\n",
    "\n",
    "allFile_list = glob.glob(os.path.join(input_file, 'news_*')) # glob함수로 news_로 시작하는 파일들을 모은다\n",
    "allData = []\n",
    "for file in allFile_list:\n",
    "    df = pd.read_csv(file) # for구문으로 csv파일들을 읽어 들인다\n",
    "    allData.append(df) # 빈 리스트에 읽어 들인 내용을 추가한다\n",
    "\n",
    "dataCombine = pd.concat(allData, axis=0, ignore_index=True) \n",
    "dataCombine.to_csv(output_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3-2. Mecab 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       IT/과학       0.82      0.69      0.75       343\n",
      "          경제       0.88      0.50      0.64       261\n",
      "          사회       0.70      0.89      0.78       611\n",
      "       생활/문화       0.77      0.77      0.77       534\n",
      "\n",
      "    accuracy                           0.76      1749\n",
      "   macro avg       0.79      0.71      0.74      1749\n",
      "weighted avg       0.77      0.76      0.75      1749\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csv_path = os.getenv(\"HOME\") + \"/workplace/aiffel/Explore/03. news_crawler/news_dataset/total_data.csv\"\n",
    "df = pd.read_table(csv_path, sep=',')\n",
    "\n",
    "df['news'] = df['news'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "df['news'] = df['news'].str.replace(\"\\n\",\"\")\n",
    "\n",
    "df.drop_duplicates(subset=['news'], inplace=True)\n",
    "\n",
    "def preprocessing(data):\n",
    "  text_data = []\n",
    "\n",
    "  for sentence in data:\n",
    "    temp_data = []\n",
    "    temp_data = tokenizer.morphs(sentence) \n",
    "    temp_data = [word for word in temp_data if not word in stopwords] \n",
    "    text_data.append(temp_data)\n",
    "\n",
    "  text_data = list(map(' '.join, text_data))\n",
    "\n",
    "  return text_data\n",
    "\n",
    "text_data = preprocessing(df['news'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_data, df['code'], random_state = 0)\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "\n",
    "def tfidf_vectorizer(data):\n",
    "  data_counts = count_vect.transform(data)\n",
    "  data_tfidf = tfidf_transformer.transform(data_counts)\n",
    "  return data_tfidf\n",
    "\n",
    "y_pred = clf.predict(tfidf_vectorizer(X_test))\n",
    "print(metrics.classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 평가\n",
    "\n",
    "4월부터 8월까지 다양한 데이터를 크롤링하여 모델을 만들었으나 정확도가 처음보다 떨어지는 결과가 나왔습니다. csv 파일을 열어 대략적인 자연어 처리가 어떤 과정을 통해 이루어지는 간단하게 이해할 수 있는 과정이었습니다. 그러나 어떻게 하면 정확도를 높일 수 있는지에 대한 약간의 힌트나 가이드가 있으면 단순 작업하는 시간을 줄이고 모델을 이해하는 데에 시간을 더 쓸 수 있을 것으로 보입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
